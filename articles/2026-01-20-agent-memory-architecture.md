---
title: "AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ - RAGã‚’è¶…ãˆãŸæ°¸ç¶šè¨˜æ†¶"
emoji: "ğŸ’¾"
type: "tech"
topics: ["ai", "llm", "rag", "vectordb", "aiagent"]
published: false
---

**ã€ŒRAGã‚’å°å…¥ã—ãŸã®ã«ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå‰å›ã®ä¼šè©±ã‚’è¦šãˆã¦ã„ãªã„ã€**

ã“ã‚Œã€RAGã®è¨­è¨ˆãƒŸã‚¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚**RAGã¯ãƒ¡ãƒ¢ãƒªã§ã¯ãªã„**ã®ã§ã™ã€‚

2026å¹´ã€æœ¬ç•ªç’°å¢ƒã§å‹•ãAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¯ã€RAGã‚’è¶…ãˆãŸ**æ°¸ç¶šãƒ¡ãƒ¢ãƒªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**ãŒå¿…è¦ã§ã™ã€‚

## RAGã®é™ç•Œã‚’ç†è§£ã™ã‚‹

### RAGãŒå¾—æ„ãªã“ã¨

```
ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã€Œè£½å“Xã®ä»•æ§˜ã‚’æ•™ãˆã¦ã€
RAG: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢ â†’ é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾— â†’ å›ç­”ç”Ÿæˆ
```

é™çš„ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆQ&Aã«ã¯æœ€é©ã€‚

### RAGãŒè‹¦æ‰‹ãªã“ã¨

```
Day 1: ã€Œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆAã®é€²æ—ã‚’å ±å‘Šã—ã¦ã€
Day 3: ã€Œå‰å›ã®å ±å‘Šã‹ã‚‰ã®å¤‰æ›´ç‚¹ã¯ï¼Ÿã€
Day 7: ã€Œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆAã§å­¦ã‚“ã ã“ã¨ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆBã«æ´»ã‹ã—ã¦ã€
```

RAGã®å•é¡Œç‚¹ï¼š
- **é™çš„ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å‰æ**: ã‚¢ã‚¤ãƒ†ãƒ ãŒæ¸›è¡°ã—ãªã„ã€æ¤œç´¢ãŒçŠ¶æ…‹ã‚’å¤‰æ›´ã—ãªã„
- **æ™‚ç³»åˆ—ç„¡è¦–**: ã€Œå‰å›ã€ã€Œå¤‰æ›´ç‚¹ã€ã¨ã„ã†æ¦‚å¿µãŒãªã„
- **ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ãªã—**: çµŒé¨“ã‹ã‚‰å­¦ç¿’ã—ãªã„

:::message alert
**é‡è¦ãªèªè­˜:** RAGã¯ã€Œæ¤œç´¢ã€ã§ã‚ã‚Šã€Œè¨˜æ†¶ã€ã§ã¯ãªã„ã€‚æ¯å›ã‚¼ãƒ­ã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å†æ§‹ç¯‰ã—ã¦ã„ã‚‹ã€‚
:::

---

## 2026å¹´ã®ãƒ¡ãƒ¢ãƒªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 4ç¨®é¡ã®ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ—

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Agent Memory                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Episodic   â”‚  Semantic   â”‚ Procedural  â”‚Associativeâ”‚
â”‚  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰  â”‚  æ„å‘³è¨˜æ†¶   â”‚  æ‰‹ç¶šãè¨˜æ†¶  â”‚ é€£æƒ³è¨˜æ†¶  â”‚
â”‚             â”‚             â”‚             â”‚           â”‚
â”‚ ã€Œä½•ãŒ      â”‚ ã€Œä½•ã‚’     â”‚ ã€Œã©ã†ã‚„ã£ã¦â”‚ ã€Œä½•ã¨    â”‚
â”‚  èµ·ããŸã‹ã€ â”‚  çŸ¥ã£ã¦ã„ã‚‹ã‹ã€â”‚ ã‚„ã‚‹ã‹ã€  â”‚ é–¢é€£ã™ã‚‹ã‹ã€â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 1. Episodic Memoryï¼ˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ï¼‰

**éå»ã®çµŒé¨“ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆã®è¨˜éŒ²**

```python
class EpisodicMemory:
    def __init__(self, vector_store):
        self.store = vector_store

    def record_episode(self, event):
        """
        ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ™‚ç³»åˆ—ã§è¨˜éŒ²
        """
        episode = {
            "timestamp": datetime.now(),
            "event_type": event.type,
            "context": event.context,
            "action_taken": event.action,
            "outcome": event.outcome,
            "embedding": self._embed(event),
        }
        self.store.insert(episode)

    def recall_similar_episodes(self, current_situation, k=5):
        """
        é¡ä¼¼ã—ãŸéå»ã®çµŒé¨“ã‚’æƒ³èµ·
        """
        query_embedding = self._embed(current_situation)
        similar = self.store.search(
            query_embedding,
            filter={"event_type": current_situation.type},
            k=k
        )
        return sorted(similar, key=lambda x: x["timestamp"], reverse=True)
```

**ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:**
- ã€Œå‰å›ã“ã®ã‚¨ãƒ©ãƒ¼ã«é­é‡ã—ãŸã¨ãã€ã©ã†è§£æ±ºã—ãŸï¼Ÿã€
- ã€Œã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®éå»ã®ã‚„ã‚Šå–ã‚Šã¯ï¼Ÿã€

#### 2. Semantic Memoryï¼ˆæ„å‘³è¨˜æ†¶ï¼‰

**äº‹å®Ÿãƒ»çŸ¥è­˜ã®è“„ç©**

```python
class SemanticMemory:
    def __init__(self, knowledge_graph):
        self.kg = knowledge_graph

    def learn_fact(self, subject, predicate, obj, confidence=1.0):
        """
        äº‹å®Ÿã‚’çŸ¥è­˜ã‚°ãƒ©ãƒ•ã«è¿½åŠ 
        """
        self.kg.add_triple(
            subject=subject,
            predicate=predicate,
            object=obj,
            metadata={
                "confidence": confidence,
                "learned_at": datetime.now(),
                "source": "interaction",
            }
        )

    def query_knowledge(self, question):
        """
        çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’ã‚¯ã‚¨ãƒª
        """
        # è‡ªç„¶è¨€èªã‚’SPARQLã«å¤‰æ›
        sparql = self._nl_to_sparql(question)
        return self.kg.query(sparql)
```

**ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:**
- ã€Œç”°ä¸­ã•ã‚“ã®æ‰€å±éƒ¨ç½²ã¯ï¼Ÿã€â†’ éå»ã®ä¼šè©±ã‹ã‚‰å­¦ç¿’ã—ãŸäº‹å®Ÿ
- ã€Œã“ã®APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¯ï¼Ÿã€â†’ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸçŸ¥è­˜

#### 3. Procedural Memoryï¼ˆæ‰‹ç¶šãè¨˜æ†¶ï¼‰

**ã€Œã©ã†ã‚„ã‚‹ã‹ã€ã®ãƒã‚¦ãƒã‚¦**

```python
class ProceduralMemory:
    def __init__(self):
        self.procedures = {}
        self.success_rates = {}

    def learn_procedure(self, task_type, steps, outcome):
        """
        ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œæ‰‹é †ã‚’å­¦ç¿’
        """
        if task_type not in self.procedures:
            self.procedures[task_type] = []

        self.procedures[task_type].append({
            "steps": steps,
            "success": outcome.success,
            "context": outcome.context,
        })

        # æˆåŠŸç‡ã‚’æ›´æ–°
        self._update_success_rate(task_type)

    def get_best_procedure(self, task_type, context):
        """
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¿œã˜ãŸæœ€é©ãªæ‰‹é †ã‚’å–å¾—
        """
        if task_type not in self.procedures:
            return None

        # æˆåŠŸã—ãŸæ‰‹é †ã®ä¸­ã‹ã‚‰ã€ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æœ€ã‚‚è¿‘ã„ã‚‚ã®ã‚’é¸æŠ
        successful = [p for p in self.procedures[task_type] if p["success"]]
        if not successful:
            return None

        return self._find_most_similar(successful, context)
```

**ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:**
- ã€Œãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †ã€â†’ éå»ã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å†ç¾
- ã€Œã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è¦³ç‚¹ã€â†’ å­¦ç¿’ã—ãŸãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

#### 4. Associative Memoryï¼ˆé€£æƒ³è¨˜æ†¶ï¼‰

**æ¦‚å¿µé–“ã®é–¢é€£æ€§**

```python
class AssociativeMemory:
    def __init__(self, graph_db):
        self.graph = graph_db

    def associate(self, concept_a, concept_b, relation_type, strength=1.0):
        """
        æ¦‚å¿µé–“ã®é–¢é€£ã‚’è¨˜éŒ²
        """
        self.graph.create_edge(
            from_node=concept_a,
            to_node=concept_b,
            relation=relation_type,
            weight=strength,
        )

    def spread_activation(self, start_concept, depth=3):
        """
        æ´»æ€§åŒ–æ‹¡æ•£: é–¢é€£æ¦‚å¿µã‚’èŠ‹ã¥ã‚‹å¼ã«å–å¾—
        """
        activated = {start_concept: 1.0}
        frontier = [start_concept]

        for _ in range(depth):
            next_frontier = []
            for concept in frontier:
                neighbors = self.graph.get_neighbors(concept)
                for neighbor, weight in neighbors:
                    if neighbor not in activated:
                        activated[neighbor] = activated[concept] * weight * 0.7
                        next_frontier.append(neighbor)
            frontier = next_frontier

        return sorted(activated.items(), key=lambda x: x[1], reverse=True)
```

**ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:**
- ã€Œèªè¨¼ã€â†’ã€Œã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€â†’ã€ŒOAuthã€â†’ã€ŒJWTã€ã¨é€£æƒ³
- æ–‡è„ˆã«å¿œã˜ãŸé–¢é€£æƒ…å ±ã®è‡ªå‹•å–å¾—

---

## ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: Vector + Graph

### ãªãœãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãŒå¿…è¦ã‹

| ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ | å¾—æ„ | è‹¦æ‰‹ |
|-----------|------|------|
| Vector DB | æ„å‘³çš„é¡ä¼¼æ€§æ¤œç´¢ | é–¢ä¿‚æ€§ã®æ¨è«– |
| Graph DB | é–¢ä¿‚æ€§ã®ãƒˆãƒ©ãƒãƒ¼ã‚¹ | é¡ä¼¼æ€§æ¤œç´¢ |
| Hybrid | ä¸¡æ–¹ | è¤‡é›‘æ€§ãŒå¢—ã™ |

### å®Ÿè£…ä¾‹: Mem0 + Neptune Analytics

```python
class HybridMemorySystem:
    def __init__(self):
        # ãƒ™ã‚¯ãƒˆãƒ«DB: æ„å‘³çš„æ¤œç´¢ç”¨
        self.vector_store = VectorStore()  # e.g., Pinecone, Weaviate

        # ã‚°ãƒ©ãƒ•DB: é–¢ä¿‚æ€§æ¨è«–ç”¨
        self.graph_store = GraphStore()    # e.g., Neptune, Neo4j

        # ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        self.mem0 = Mem0Client()

    def store(self, memory_item):
        """
        ãƒ¡ãƒ¢ãƒªã‚’ä¸¡æ–¹ã®ã‚¹ãƒˆã‚¢ã«ä¿å­˜
        """
        # ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦ä¿å­˜
        embedding = self._embed(memory_item.content)
        vector_id = self.vector_store.upsert(
            id=memory_item.id,
            vector=embedding,
            metadata=memory_item.metadata,
        )

        # ã‚°ãƒ©ãƒ•ã«å®Ÿä½“ã¨é–¢ä¿‚ã‚’æŠ½å‡ºã—ã¦ä¿å­˜
        entities = self._extract_entities(memory_item.content)
        relations = self._extract_relations(memory_item.content)

        for entity in entities:
            self.graph_store.upsert_node(entity)

        for relation in relations:
            self.graph_store.upsert_edge(relation)

        # Mem0ã§çµ±åˆç®¡ç†
        self.mem0.add(memory_item)

    def retrieve(self, query, strategy="hybrid"):
        """
        ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
        """
        if strategy == "vector":
            return self._vector_search(query)
        elif strategy == "graph":
            return self._graph_traverse(query)
        else:  # hybrid
            # 1. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§å€™è£œã‚’å–å¾—
            vector_results = self._vector_search(query, k=20)

            # 2. ã‚°ãƒ©ãƒ•ã§é–¢ä¿‚æ€§ã‚’æ‹¡å¼µ
            expanded = []
            for result in vector_results[:5]:
                related = self.graph_store.multi_hop_query(
                    start=result.id,
                    hops=2,
                )
                expanded.extend(related)

            # 3. çµæœã‚’ãƒãƒ¼ã‚¸ã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            return self._merge_and_rank(vector_results, expanded, query)
```

### Multi-hop Reasoning

ã‚°ãƒ©ãƒ•DBã®çœŸä¾¡ã¯**å¤šæ®µéšæ¨è«–**ï¼š

```python
def multi_hop_query(self, question):
    """
    ã€Œç”°ä¸­ã•ã‚“ãŒæ‹…å½“ã—ã¦ã„ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®æ¥­ç•Œã¯ï¼Ÿã€
    ç”°ä¸­ â†’ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ â†’ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ â†’ æ¥­ç•Œ
    """
    # 1. è³ªå•ã‹ã‚‰ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨é–¢ä¿‚ã‚’æŠ½å‡º
    entities = self._extract_entities(question)  # ["ç”°ä¸­"]
    path_pattern = self._infer_path(question)    # [æ‹…å½“, ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ, æ¥­ç•Œ]

    # 2. ã‚°ãƒ©ãƒ•ã‚’ãƒˆãƒ©ãƒãƒ¼ã‚¹
    results = self.graph_store.traverse(
        start=entities[0],
        path=path_pattern,
    )

    return results
```

---

## ãƒ¡ãƒ¢ãƒªã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†

### Memory Decayï¼ˆè¨˜æ†¶æ¸›è¡°ï¼‰

äººé–“ã®è¨˜æ†¶ã¨åŒæ§˜ã€ä½¿ã‚ã‚Œãªã„è¨˜æ†¶ã¯è–„ã‚Œã‚‹ã¹ãï¼š

```python
class MemoryDecay:
    def __init__(self, half_life_days=30):
        self.half_life = half_life_days

    def calculate_strength(self, memory_item):
        """
        æ™‚é–“çµŒéã«ã‚ˆã‚‹è¨˜æ†¶å¼·åº¦ã®æ¸›è¡°
        """
        age_days = (datetime.now() - memory_item.created_at).days
        base_strength = memory_item.importance

        # æŒ‡æ•°é–¢æ•°çš„æ¸›è¡°
        decay_factor = 0.5 ** (age_days / self.half_life)

        # ã‚¢ã‚¯ã‚»ã‚¹é »åº¦ã«ã‚ˆã‚‹ãƒ–ãƒ¼ã‚¹ãƒˆ
        access_boost = min(memory_item.access_count * 0.1, 1.0)

        return base_strength * decay_factor * (1 + access_boost)

    def should_forget(self, memory_item, threshold=0.1):
        """
        è¨˜æ†¶ã‚’å¿˜ã‚Œã‚‹ã¹ãã‹åˆ¤å®š
        """
        return self.calculate_strength(memory_item) < threshold
```

### Memory Consolidationï¼ˆè¨˜æ†¶ã®çµ±åˆï¼‰

é¡ä¼¼ã—ãŸè¨˜æ†¶ã‚’çµ±åˆã—ã¦åŠ¹ç‡åŒ–ï¼š

```python
class MemoryConsolidation:
    def consolidate(self, memories):
        """
        é¡ä¼¼ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã¦çµ±åˆ
        """
        # 1. ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        clusters = self._cluster_by_similarity(memories, threshold=0.85)

        consolidated = []
        for cluster in clusters:
            if len(cluster) == 1:
                consolidated.append(cluster[0])
            else:
                # è¤‡æ•°ã®é¡ä¼¼ãƒ¡ãƒ¢ãƒªã‚’1ã¤ã«çµ±åˆ
                merged = self._merge_memories(cluster)
                consolidated.append(merged)

        return consolidated

    def _merge_memories(self, memories):
        """
        è¤‡æ•°ã®ãƒ¡ãƒ¢ãƒªã‚’çµ±åˆ
        """
        # æœ€ã‚‚é‡è¦ãªãƒ¡ãƒ¢ãƒªã‚’ãƒ™ãƒ¼ã‚¹ã«
        base = max(memories, key=lambda m: m.importance)

        # ä»–ã®ãƒ¡ãƒ¢ãƒªã‹ã‚‰è¿½åŠ æƒ…å ±ã‚’æŠ½å‡º
        additional_info = []
        for m in memories:
            if m.id != base.id:
                unique = self._extract_unique_info(m, base)
                additional_info.extend(unique)

        # çµ±åˆãƒ¡ãƒ¢ãƒªã‚’ç”Ÿæˆ
        return Memory(
            content=f"{base.content}\n\nè¿½åŠ æƒ…å ±:\n" + "\n".join(additional_info),
            importance=base.importance,
            metadata={**base.metadata, "consolidated_from": [m.id for m in memories]},
        )
```

---

## å®Ÿè·µ: Mem0ã‚’ä½¿ã£ãŸå®Ÿè£…

[Mem0](https://github.com/mem0ai/mem0)ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¡ãƒ¢ãƒªã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã«ãªã‚Šã¤ã¤ã‚ã‚Šã¾ã™ã€‚

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```python
from mem0 import Memory

# åˆæœŸåŒ–
memory = Memory()

# ãƒ¡ãƒ¢ãƒªã®è¿½åŠ 
memory.add(
    "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯Pythonã‚’å¥½ã¿ã€TypeScriptã‚‚ä½¿ã†",
    user_id="user_123",
    metadata={"type": "preference"}
)

# ãƒ¡ãƒ¢ãƒªã®æ¤œç´¢
results = memory.search(
    "ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯",
    user_id="user_123"
)

# ãƒ¡ãƒ¢ãƒªã®æ›´æ–°ï¼ˆè‡ªå‹•ã§é‡è¤‡æ’é™¤ãƒ»çµ±åˆï¼‰
memory.add(
    "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æœ€è¿‘Rustã‚‚å­¦ã³å§‹ã‚ãŸ",
    user_id="user_123",
)
```

### ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®çµ±åˆ

```python
class MemoryAwareAgent:
    def __init__(self, llm, memory):
        self.llm = llm
        self.memory = memory

    async def respond(self, user_id, message):
        # 1. é–¢é€£ã™ã‚‹è¨˜æ†¶ã‚’å–å¾—
        memories = self.memory.search(message, user_id=user_id, limit=10)

        # 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        context = self._build_context(memories)

        # 3. LLMã§å¿œç­”ç”Ÿæˆ
        response = await self.llm.generate(
            system=f"ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„:\n{context}",
            user=message,
        )

        # 4. æ–°ã—ã„æƒ…å ±ã‚’ãƒ¡ãƒ¢ãƒªã«è¿½åŠ 
        new_info = self._extract_memorable_info(message, response)
        for info in new_info:
            self.memory.add(info, user_id=user_id)

        return response
```

---

## 2026å¹´ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### ãƒ¡ãƒ¢ãƒªã‚¹ã‚¿ãƒƒã‚¯ã®æ¨å¥¨æ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Application Layer                        â”‚
â”‚         (Your Agent / Application)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚             Mem0 (Memory Management)                 â”‚
â”‚    æŠ½å‡ºãƒ»çµ±åˆãƒ»æ¤œç´¢ãƒ»ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Vector Store    â”‚    Graph Store                  â”‚
â”‚   (Semantic)      â”‚    (Relational)                 â”‚
â”‚   Pinecone/       â”‚    Neptune/                     â”‚
â”‚   Weaviate        â”‚    Neo4j                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚             Object Storage (Archival)                â”‚
â”‚                    S3 / GCS                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è©•ä¾¡æŒ‡æ¨™

| æŒ‡æ¨™ | èª¬æ˜ | ç›®æ¨™å€¤ |
|------|------|--------|
| Memory Reuse Rate | è¨˜æ†¶ã®å†åˆ©ç”¨ç‡ | > 50% |
| Retrieval Precision | æ¤œç´¢ç²¾åº¦ | > 90% |
| Consolidation Ratio | çµ±åˆã«ã‚ˆã‚‹åœ§ç¸®ç‡ | 30-50% |
| Decay False Positive | èª¤ã£ã¦å¿˜ã‚ŒãŸé‡è¦è¨˜æ†¶ | < 5% |

---

## ã¾ã¨ã‚

:::message
**æ ¸å¿ƒ:** RAGã¯ã€Œæ¤œç´¢ã€ã€ãƒ¡ãƒ¢ãƒªã¯ã€ŒçµŒé¨“ã®è“„ç©ã¨å­¦ç¿’ã€ã€‚
æœ¬ç•ªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¯ä¸¡æ–¹ãŒå¿…è¦ã ãŒã€å½¹å‰²ã¯å…¨ãç•°ãªã‚‹ã€‚
:::

### é‡è¦ãƒã‚¤ãƒ³ãƒˆ

1. **4ç¨®é¡ã®ãƒ¡ãƒ¢ãƒª**: Episodic, Semantic, Procedural, Associative
2. **Hybrid Architecture**: Vector + Graph ã®çµ„ã¿åˆã‚ã›
3. **ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†**: Decay ã¨ Consolidation
4. **å®Ÿè£…**: Mem0 + Vector Store + Graph Store

### 2026å¹´ã®ç¾å®Ÿ

> ã€Œ2025å¹´ã®ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ‡ãƒ¢ã¯ã€å˜ä¸€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯è³¢ãè¦‹ãˆã‚‹ãŒã€å®Ÿä¸–ç•Œã§ã¯å¤±æ•—ã™ã‚‹ã€‚2026å¹´ã€ãã®é•ã„ãŒãƒ‘ã‚¤ãƒ­ãƒƒãƒˆã¨ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ èƒ½åŠ›ã®å·®ã«ãªã‚‹ã€‚ã€

---

## å‚è€ƒãƒªãƒ³ã‚¯

- [Mem0 - Memory Layer for AI](https://github.com/mem0ai/mem0)
- [Design Patterns for Long-Term Memory in LLM Architectures](https://serokell.io/blog/design-patterns-for-long-term-memory-in-llm-powered-architectures)
- [AWS - Build Persistent Memory with Mem0](https://aws.amazon.com/blogs/database/build-persistent-memory-for-agentic-ai-applications-with-mem0-open-source-amazon-elasticache-for-valkey-and-amazon-neptune-analytics/)
- [A 2026 Memory Stack for Enterprise Agents](https://alok-mishra.com/2026/01/07/a-2026-memory-stack-for-enterprise-agents/)

---

**ã‚ãªãŸã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã¯ã©ã‚“ãªãƒ¡ãƒ¢ãƒªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ã£ã¦ã„ã¾ã™ã‹ï¼Ÿèª²é¡Œã‚„å·¥å¤«ãŒã‚ã‚Œã°ã‚³ãƒ¡ãƒ³ãƒˆã§å…±æœ‰ã—ã¦ãã ã•ã„ï¼**
