---
title: "【悲報】AIコーディングツール、実は生産性を19%下げていた件【METR研究】"
emoji: "💀"
type: "tech"
topics: ["ai", "cursor", "copilot", "開発効率", "プログラミング"]
published: true
---

**炎上覚悟で言います。**

Cursor、GitHub Copilot、Claude Code...これらのAIコーディングツールを使って「効率上がったわ〜」と思っているあなた。

**それ、錯覚です。**

2025年に発表されたMETR（Model Evaluation & Threat Research）の研究で、衝撃的な結果が出ました。

:::message alert
AIツールを使った開発者は、使わなかった開発者より**19%遅かった**。
しかも本人たちは「24%速くなった」と信じていた。
:::

## 結論から言うと

AIコーディングツールは：
- **初心者には効果あり**（20-55%の生産性向上）
- **経験豊富な開発者には逆効果**（19%の生産性低下）
- **でも全員が「速くなった」と錯覚する**

これ、マジでヤバくないですか？

## METR研究の衝撃的な内容

### 実験概要

| 項目 | 内容 |
|------|------|
| 参加者 | 16人の経験豊富なOSS開発者 |
| タスク数 | 246タスク |
| 開発者の経験 | 対象プロジェクトで平均5年 |
| 実験方法 | ランダム化比較試験（RCT） |

RCTは医薬品の効果を測る「ゴールドスタンダード」。つまり、**科学的に最も信頼性の高い方法**で測定されたということ。

### 結果

```
開発者の予測：「AIで24%速くなるはず」
実験後の体感：「20%速くなった気がする」
実際の結果：19%遅くなっていた
```

**認知バイアスの教科書みたいな結果**です。

## なぜAIは開発者を遅くするのか？

### 1. コンテキストスイッチングのコスト

AIの提案を読む → 検証する → 修正する → また提案を見る...

このループが**フロー状態を破壊**します。

```
従来の開発フロー：
考える → 書く → テスト → 修正

AI利用時のフロー：
考える → AIに聞く → 提案を読む → 検証 → 部分採用 →
修正 → また聞く → また検証 → ...
```

### 2. 「レビュー負荷」の転嫁

GitHubの内部調査で判明した事実：

- Copilot導入後、ジュニア開発者のコード量は**増加**
- しかしそのコードは**リワーク（手直し）が必要**
- シニア開発者のレビュー負荷が**6.5%増加**
- シニア開発者自身の生産性は**19%低下**

:::message
つまり、AIは「初心者の生産性を上げる代わりに、ベテランの生産性を下げる」という**ゼロサムゲーム**だった。
:::

### 3. 過信による品質低下

Stack Overflow 2025調査より：

- 「AIで大幅に生産性向上」と答えた開発者：**16.3%のみ**
- 「効果なし・ほぼなし」と答えた開発者：**41.4%**

でも企業は「AI導入で生産性向上！」と言い続けている。なぜか？

**ベンダー（GitHub、Google、Microsoft）が出す数字だから**です。

## AIコーディングツールが有効なケース

ポジショントークなしで整理すると：

### 効果が高い

- **初心者・学習者**：知らない言語やフレームワークの学習
- **ボイラープレート生成**：テストコード、設定ファイル
- **単純な変換作業**：フォーマット変換、リファクタリング
- **ドキュメント作成**：コメント、README

### 効果が低い・逆効果

- **複雑なビジネスロジック**：AIはコンテキストを理解できない
- **レガシーコード修正**：既存の設計意図を把握できない
- **アーキテクチャ設計**：全体像の把握が必要
- **デバッグ**：原因特定より「それっぽい修正」を提案しがち

## 2026年の現実：「Lonely Agent」問題

Salesforce/SlackのCMO、Ryan Gavin氏の予測：

> 「2026年は"Lonely Agent"の年になる。企業は従業員1人あたり数百のエージェントを作るが、**ほとんどは使われないソフトウェアライセンスのように放置される**」

実際、Databricksの調査では：

- AIエージェント導入企業の**327%増加**
- しかし「実際に業務で使われている」割合は**不明**

これ、SaaSあるあるの「買ったけど使ってない」と同じ構図ですよね。

## じゃあどうすればいいの？

### 1. 効果測定をちゃんとやる

「速くなった気がする」ではなく、**実際のリードタイム**を測る。

```bash
# 例：PRのリードタイム測定
git log --pretty=format:"%h %ad %s" --date=short | head -100
```

### 2. 用途を絞る

全部AIに任せるのではなく、**効果が高い作業だけ**に使う。

私の使い分け：

| 作業 | AI使用 |
|------|--------|
| テストコード生成 | ✅ 使う |
| ボイラープレート | ✅ 使う |
| コアロジック実装 | ❌ 使わない |
| デバッグ | ❌ 使わない |
| コードレビュー | ⚠️ 参考程度 |

### 3. 「AIを使わない」選択肢を持つ

これが一番大事。

AIコーディングツールを**常にON**にしていると、思考がAIに依存します。

週に1日は「AIなしデー」を作って、自分の生産性を確認してみてください。

## まとめ

- AIコーディングツールは**経験者を遅くする**（METR研究）
- でも全員が**「速くなった」と錯覚**する（認知バイアス）
- 初心者には効果あるが、**シニアの負荷が増える**
- 2026年は**使われないAIエージェントが大量発生**する予測

---

**異論がある方、コメントで教えてください。**

特にCursor愛用者の方、「いや俺は本当に速くなってる」というデータがあれば見せてほしいです。

## 参考文献

- [METR: Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/)
- [MIT Technology Review: AI coding is now everywhere. But not everyone is convinced.](https://www.technologyreview.com/2025/12/15/1128352/rise-of-ai-coding-developers-2026/)
- [The AI Productivity Paradox: Why Developers Are 19% Slower](https://dev.to/increase123/the-ai-productivity-paradox-why-developers-are-19-slower-and-what-this-means-for-2026-a14)
- [Axios: AI 2026 trends: bubbles, agents, demand for ROI](https://www.axios.com/2026/01/01/ai-2026-money-openai-google-anthropic-agents)
